# GPT2诗词生成模型
[ *自然语言处理 · 个人项目* ],
date[ 2024 年 04 月 – 2024 年 05 月 ]

基于 GPT2 预训练语言模型的中文诗词数据集微调，用户可以指定诗体、藏字生成对应诗词文本

- 整理大量诗词文本数据并进行训练预处理，包含 56 万余首唐诗宋词数据
- Tokenize 原始数据文本，基于 Pytorch 实现模型的分批次的优化微调
- 用户可以指定诗体和藏头字，模型需要通过用户的输入作为起始文本，生成对应的诗词文本
- 基于 Streamlit 实现搭建前端用户交互平台界面，用户可以通过平台可以直观地与模型互动，并即时获得由模型生成的诗词所对应的软笔书法图像
